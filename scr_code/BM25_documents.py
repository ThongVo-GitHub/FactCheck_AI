import os, re, math, pickle
import pandas as pd
import numpy as np
from tqdm import tqdm

# ========================== C·∫§U H√åNH ==========================
TRAIN_CSV = r"D:/Code_cuaThong/GPPM_2025/train_data.csv"
DEV_CSV   = r"D:/Code_cuaThong/GPPM_2025/dev_data.csv"
TEST_CSV  = r"D:/Code_cuaThong/GPPM_2025/test_data.csv"
OUT_DIR   = r"D:/Code_cuaThong/GPPM_2025/indices"

MIN_WORDS = 4
ADD_STATEMENTS = True  # g·ªôp th√™m Statement v√†o corpus
SAVE_RERANK_READY = True  # l∆∞u th√™m file cho reranking

# ========================== H√ÄM H·ªñ TR·ª¢ ==========================
def convert_to_list(value):
    import ast
    try:
        return ast.literal_eval(value)
    except (ValueError, SyntaxError):
        return value

def read_dataset(path):
    df = pd.read_csv(path)
    if "evidence_top5" in df.columns:
        df = df.drop(columns=["evidence_top5"])
    for col in ["splited_sentences", "Evidence_List"]:
        if col in df.columns:
            df[col] = df[col].apply(convert_to_list)
    return df

# ========================== BM25 ==========================
class BM25Okapi:
    def __init__(self, corpus, k1=1.5, b=0.75, epsilon=0.25):
        self.k1, self.b, self.epsilon = k1, b, epsilon
        self.corpus_size = len(corpus)
        if self.corpus_size == 0:
            raise ValueError("Corpus r·ªóng. Kh√¥ng th·ªÉ build BM25.")
        self.doc_freqs = []
        self.idf = {}
        self.doc_len = [len(doc) for doc in corpus]
        self.avgdl = sum(self.doc_len) / self.corpus_size
        self._initialize(corpus)

    def _initialize(self, corpus):
        nd = {}
        for document in corpus:
            freqs = {}
            for w in document:
                freqs[w] = freqs.get(w, 0) + 1
            self.doc_freqs.append(freqs)
            for w in freqs:
                nd[w] = nd.get(w, 0) + 1
        self._calc_idf(nd)

    def _calc_idf(self, nd):
        idf_sum = 0
        neg = []
        for w, df in nd.items():
            idf = math.log(self.corpus_size - df + 0.5) - math.log(df + 0.5)
            self.idf[w] = idf
            idf_sum += idf
            if idf < 0:
                neg.append(w)
        self.average_idf = idf_sum / max(len(self.idf), 1)
        eps = self.epsilon * self.average_idf
        for w in neg:
            self.idf[w] = eps

    def get_scores(self, query_tokens):
        score = np.zeros(self.corpus_size, dtype=np.float32)
        doc_len = np.array(self.doc_len, dtype=np.float32)
        for q in query_tokens:
            q_freq = np.array([doc.get(q, 0) for doc in self.doc_freqs], dtype=np.float32)
            denom = q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)
            score += (self.idf.get(q, 0.0)) * (q_freq * (self.k1 + 1) / np.where(denom == 0, 1, denom))
        return score

# ========================== TI·ªÄN X·ª¨ L√ù TV ==========================
VI_CHARS = "a-zA-Z0-9√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠ƒë√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ"
VI_KEEP  = f"[^{VI_CHARS} ]"

def clean_text(s: str) -> str:
    s = str(s).replace("\n", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def tokenize_vi(s: str):
    s = s.lower()
    s = re.sub(VI_KEEP, " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s.split()

# ========================== MAIN ==========================
def main():
    os.makedirs(OUT_DIR, exist_ok=True)

    # Ki·ªÉm tra file
    for p in [TRAIN_CSV, DEV_CSV, TEST_CSV]:
        if not os.path.isfile(p):
            raise FileNotFoundError(f"Kh√¥ng th·∫•y file: {p}")

    print("üìñ ƒê·ªçc d·ªØ li·ªáu‚Ä¶")
    train = read_dataset(TRAIN_CSV)
    dev   = read_dataset(DEV_CSV)
    test  = read_dataset(TEST_CSV)
    all_df = pd.concat([train, dev, test], ignore_index=True)

    # Gom documents
    print("üß© Gom documents t·ª´ 'splited_sentences'‚Ä¶")
    documents = []
    if "splited_sentences" in all_df.columns:
        for lst in tqdm(all_df["splited_sentences"], total=len(all_df)):
            if isinstance(lst, list):
                for s in lst:
                    if isinstance(s, str):
                        s2 = clean_text(s)
                        if len(s2.split()) >= MIN_WORDS:
                            documents.append(s2)

    # Th√™m Statement v√†o corpus
    if ADD_STATEMENTS and "Statement" in all_df.columns:
        print("‚ûï Th√™m Statement v√†o corpus‚Ä¶")
        for s in tqdm(all_df["Statement"].fillna("").astype(str).tolist()):
            s2 = clean_text(s)
            if len(s2.split()) >= MIN_WORDS:
                documents.append(s2)

    # Lo·∫°i tr√πng
    documents = list(dict.fromkeys(documents))
    print(f"üìä T·ªïng s·ªë documents: {len(documents):,}")

    # Ghi file documents.txt
    doc_path = os.path.join(OUT_DIR, "documents.txt")
    with open(doc_path, "w", encoding="utf-8") as f:
        for d in documents:
            f.write(d + "\n")
    print(f"‚úÖ Ghi xong {doc_path}")

    # Tokenize corpus
    print("üî§ Tokenize corpus‚Ä¶")
    tokenized_corpus = [tokenize_vi(d) for d in tqdm(documents, total=len(documents))]

    # Build BM25
    print("‚öôÔ∏è Build BM25 Okapi‚Ä¶")
    bm25 = BM25Okapi(tokenized_corpus)

    pkl_path = os.path.join(OUT_DIR, "bm25_index.pkl")
    with open(pkl_path, "wb") as f:
        pickle.dump(bm25, f)
    print(f"‚úÖ L∆∞u xong {pkl_path}")

    # (T√πy ch·ªçn) Chu·∫©n b·ªã file cho b∆∞·ªõc Semantic Reranking
    if SAVE_RERANK_READY:
        rerank_ready = {
            "documents": documents,
            "tokenized_corpus": tokenized_corpus
        }
        pkl_rerank = os.path.join(OUT_DIR, "rerank_ready.pkl")
        with open(pkl_rerank, "wb") as f:
            pickle.dump(rerank_ready, f)
        txt_rerank = os.path.join(OUT_DIR, "rerank_ready.txt")
        with open(txt_rerank, "w", encoding="utf-8") as f:
            for d in documents:
                f.write(d + "\n")
        print(f"üíæ L∆∞u d·ªØ li·ªáu s·∫µn cho Semantic Reranking: {pkl_rerank}, {txt_rerank}")

    print("üéâ Ho√†n t·∫•t x√¢y d·ª±ng BM25 v√† d·ªØ li·ªáu reranking!")

# ==========================================================
if __name__ == "__main__":
    main()
